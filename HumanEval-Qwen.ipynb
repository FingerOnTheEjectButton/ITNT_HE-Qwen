{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d06acd89-f45c-4ab8-9c8c-378fce9963d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from human_eval.data import read_problems, write_jsonl\n",
    "from human_eval.evaluation import evaluate_functional_correctness\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6eaa4f-4357-4eb3-90ec-f02e5c180c9f",
   "metadata": {},
   "source": [
    "Локальный сервер LM Studio + default API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ff90c5e-0176-476c-aff4-1998d87a73df",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai = OpenAI(base_url='http://127.0.0.1:1234/v1', api_key=\"lm-studio\")\n",
    "model = \"qwen2.5-3b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1efce23b-fa45-450c-a473-82759b192246",
   "metadata": {},
   "outputs": [],
   "source": [
    "problems = read_problems()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b0b67d-935e-46d4-965b-a1b317885242",
   "metadata": {},
   "source": [
    "Температуры для сэтов генерации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38b0315c-34fe-49b1-bf1e-8d292a995ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "temperatures = [0.1, 0.3, 0.5, 0.7, 0.9]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ec8a0d-5f75-48e0-aba9-a572f1364042",
   "metadata": {},
   "source": [
    "Количество токенов для одной генерации и количество генераций на задачу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec56d27f-af98-412c-83da-d14638017908",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "num_samples_per_task = 25\n",
    "max_tokens = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2327f489-e374-427a-ace5-15327b574e4d",
   "metadata": {},
   "source": [
    "Генерация ответа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e18a4b81-106a-4193-af73-5f7c2f13b579",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_code(openai, model, prompt, temperature, num_samples, max_tokens):\n",
    "    responses = []\n",
    "    for _ in range(num_samples):\n",
    "        completion = openai.completions.create(\n",
    "            model=model,\n",
    "            prompt=prompt,\n",
    "            max_tokens=max_tokens,\n",
    "            temperature=temperature\n",
    "        )\n",
    "        responses.append(completion.choices[0].text)\n",
    "    return responses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62cfe156-dfd8-4934-bdb9-80ec87233d7b",
   "metadata": {},
   "source": [
    "Сбор jsonl для одной температуры (поочередно) с генерацией по указанному количеству samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02b547be-25f1-4dee-a63a-5279decfb115",
   "metadata": {},
   "outputs": [],
   "source": [
    "for temp in temperatures:\n",
    "    samples_file = f\"samples_temp_{temp}.jsonl\"\n",
    "    if not os.path.exists(samples_file):\n",
    "        print(f\"Генерируем {num_samples_per_task} выборок при temperature={temp}...\")\n",
    "        samples = []\n",
    "        for task_id, task in problems.items():\n",
    "            prompt = task[\"prompt\"]\n",
    "            completions = generate_code(openai, model, prompt, temperature=temp, num_samples=num_samples_per_task, max_tokens=max_tokens)\n",
    "            for comp in completions:\n",
    "                samples.append({\"task_id\": task_id, \"completion\": comp})\n",
    "        write_jsonl(samples_file, samples)\n",
    "        print(f\"Сохранено {len(samples)} выборок в файл {samples_file}\")\n",
    "    else:\n",
    "        print(f\"Файл {samples_file} уже существует, используем его.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d37c975-9acf-4404-a93c-2226de5ee915",
   "metadata": {},
   "source": [
    "Оценка полученного набора генераций по pass@25 через evaluate_function_correctness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951d77c0-7959-44d9-acd7-13f62b9f584d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for temp in temperatures:\n",
    "    samples_file = f\"samples_temp_{temp}.jsonl\"\n",
    "    eval_result = evaluate_functional_correctness(samples_file, k=[25])\n",
    "    pass_at_1 = eval_result.get('pass@25', None)\n",
    "    results[temp] = pass_at_25\n",
    "    print(f\"temperature={temp}: pass@1 = {pass_at_25}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd64e075-9926-4557-829a-e36274a61874",
   "metadata": {},
   "source": [
    "Построение простого графика для визуальной оценки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62090638-6bbc-4a91-8e0d-9d40d29f6d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(list(results.keys()), list(results.values()), marker='o')\n",
    "plt.xlabel(\"Temperature\")\n",
    "plt.ylabel(\"pass@25\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
